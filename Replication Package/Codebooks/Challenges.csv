#,Category,Subcategory,Definition,Example
1,Model Usage and Understanding,Understanding Model Function,"Issues regarding understanding of the user about the model definition, their implementation, their functionalities, and their use-cases. ","T639: ""I recently raised an issue 39 asking why the lm_head layer is not a parameters. The response I got is that “It is tied to the input layer”. After reading the docs as suggested I found that the lm_head layer is a “linear layer with weights tied to the input embeddings”. I still don’t understand what that means, as I thought the lm_head layer would output a tensor shaped (*, vocab_size) whereas the embedding is shaped (vocab_size, embedding_size)? Does that mean if I want to fine-tune the lm_head layer, I would need to fine-tune the embedding layer (wte)?"""
,,Customizing Model,"Questions related to customizing models, or using, training or deploying customized models.","T28684: ""I’m trying to fine-tune a T5 model (T5ForConditionalGeneration) with customizing 2D attention mask to 3D. I followed most (maybe all?) the tutorials, notebooks and code snippets from the Transformers library to understand what to do (thank you for the sources), but so far, I’m getting errors when I edited the modeling_t5.[...]What am I missing here? Should I add(edit) more things in modeling_t5.py?"""
,,Model Evaluation & Comparison,"Issues related to evaluating models, the related datasets (e.g. GLUE benchmarks) and comparing the performance of different models.","T7125: ""One important aspect that should also be discussed a bit is how the pretrained RoBERTa model should be evaluated ? Maybe on XTREME 2 after pretraining?"""
,,Model Converting (ONNX Library),"Questions regarding models converted (e.g. using the ONNX library) and converting models, and utilizing, fine-tuning, or deploying converted models.","T23166: ""Hi, I’m trying to export a given LayoutLMv3 fine tuned model to onnx format following this guide [...]When I’m trying to run the command from the tutorial (python -m transformers.onnx --model=nielsr/layoutlmv3-finetuned-cord onnx/) I get this error[...]Am I doing something wrong?"""
,,Loading/Saving Models,Issues that are related to loading or saving models at all stages. ,"T11565: ""I’m fine-tuning an mt5 model for my task; after training, I got an error when I wanted to save my PyTorch model with model.save_pretrained(save_directory) command. The error is[...]Does anybody know why this happened?"""
,,Model Configuration,"Questions regarding how to configue models, meaning of parameters in configuration files. ","T39525: ""What’s the meaning of offset_alibi in config.json? It’s not used in Bloom’s source codes. Does it make sense?"""
,,Model card,Questions regarding making and understanding model cards.,"T40224: "" want to create a dataset card in multiples languages. But I don’t know if there are recommendations about how name the differents files (README.md) and how show visitors the multilanguage support"""
2,Training Pipeline,Training,Issues encountered when training models.,"T9546: ""I am trying to adapt the official Google Colab 5 for language generation to tensorflow and everything seems to work wonderfully by simply appending TF to most of the huggingface function calls (TFAutoModel, etc). Unfortunately, this strategy fails at the training step[...]I have absolutely no idea what this cardinality is. Do you know what the issue can be?"""
,,Fine-Tuning,Issues encountered when fine-tuning models.,"T28446: ""I was trying to finetune BLIP and so far I got an error, not sure how to solve it. Is it possible that you can give me some advice?"""
,,Tokenization,Issues with tokenization and questions about different tokenizers,"T6258: ""Is there a way to breakdown text into the most granular form that can be applied to any model? (For instance IOB, tagging, tokens etc?)"""
,,Pretraining,Issues encountered when pre-training models. ,"T28318: ""I want to pre-train BERT from scratch on a domain-specific dataset. How should I go with it? I tried some code online but ran into issues."""
3,Memory & Performance,GPU & Optimization,"Issues encountered when using GPUs, multi-processing, distributed processing, optimizing the training (e.g. using Accelerate library)","T10967: ""I’m training my own prompt-tuning model using transformers package [...] I’m training environment is the one-machine-multiple-gpu setup [...] the Accelerator fails to work properly. It just puts everything on gpu:0, so I cannot use mutliple gpus."""
,,Speed,"Issues about the slow speed in different stages of the training pipeline, using different datasets.","T16328: ""When i used the dataset A [...] the training speed for each iteration was acceptable. However, when i changed to a larger dataset B [...] the training speed for each iteration became much slower [...]Am I missing something important?"""
,,Memory,"All issues related to the memory usage, optimizations, lack of memory.","T18898: ""I have been trying to train a model [...] Training begins but seems to fill up /dev/sdb1 location which has a total of 119 GB. This happens even when i force the cache to be on a different drive [...] Any ideas"""
,,Large Files,"Issues regarding handling, downloading, uploading large files of models.","T4081: ""I am facing similar issues, attempting to upload a large file (just above 5GB) using git-lfs. I have a dual boot on my machine, and unfortunately did not manage to upload neither from Windows or Ubuntu 18.04 [...] I read that git-lfs has issues for files larger than 4GB on windows - but I am surprised to face issues on my Ubuntu partition. Am I missing something?"""
4,External Platforms & Libraries,External Platform/Library,Issues regarding  or cuased by using external platforms and libraries that are not officially collaborating with HF. Installing and using depenedncies for HF models or spaces.,"T13503: ""The boxplot on the output of my gradio interface cuts off just below the x-axis so you can’t see the titles.[...] Has anyone had much luck with seaborn plot outputs with Gradio?"""
,,Amazon,"Issues regarding all the Amazon services and platforms that are integrated with HF, e.g. AWS, Sagemaker, etc.","T19981: ""I’m using a notebook in AWS Sagemaker [...] It works without problem in Google Colab but not in an AWS Sagemaker notebook: in an AWS Sagemaker notebook, I can not import a class ORTModelFor(…). Do you know why?"""
,,Gradio,Issues regarding the platform Gradio which isused when making spaces.,"T27346: ""I implemented a Gradio app and it seems to run very fast locally with the local link. When I tried to run the same app on public link, the model worked much much slower. Do you guys have any idea?"""
,,Kaggle,Issues regarding using kaggle notebooks or datasets.,"T28353: ""Hey guys , i am facing a problem and can’t login through token in kaggle notebook. !huggingface-cli login [...] In opposite Google colab working fine [...] Any solution?"""
,,Databricks,Issues regarding working with HF from Databricks notebooks.,"T19241: ""I’m running transformers in a Databricks notebook with a local dataset. [...] The problem comes when I want to push the model back to my account on the hub. Has anybody succeeded in connecting to their account from a DataBricks notebook?"""
,,DL framework,"Issues regarding using HF models in integration with DL frameworks (PyTorch and TensorFlow), or issues caused by them.","T4558: ""So i was stuck the whole day because of segmentation faults until I found this issue: https://github.com/pytorch/pytorch/issues/54752 13 TLDR: do not use torch.set_num_threads()"
,,Google Colab,Issues regarding working with HF from Google Colab notebooks.,"T4558: ""I run into a pretty basic problem when downloading the data. Everytime, both in Google Colab and on OVHCloud the download stops at exactly 79%. [...] Can anybody hint me to a solution?"""
5,Tutorial & Documentation,Lack of Documentation,"Users pointing out lack of documentation about a particular subject, e.g. model, task, API, etc.","T29423: ""Could you please enumerate pros and cons for both these dataset builder classes. I couldn’t find anything in the documentation. When would I prefer one over the other. Is ArrowBasedBuilder more performant for large datasets?"""
,,Official Examples and Tutorials,"Issues that happens following official HF tutorials, examples, documentation code, or notebooks. Pointing out lack of official tutorials/examples or asking for examples/tutorials for a specific subject.","T14815: ""I am trying to train a Q/A model with example script for Question Answering for Tensorflow. [...]after the script finishes the training I cannot find the trained model in output directory [...] So what am I doing wrong?"""
6,Dataset Acquisition & Usage,Custom Datasets,"Questiosn about making, uploading, using or training with customized datasets.","T8515: ""I am currently creating a dataset where the semantics of a split make no sense. It’s an Information Retrieval corpus that should not be split. [...] Can I use other strings to name the splits? Can I leave out splits altogether for a given self.config.name?"""
,,Data Preparation,"Questions and issues about preparing datasets to be used in the training pipeline, e.g. splitting the dataset, feature types, data types, input format, etc.","T28609: ""I want to finetune the GPT-Neo model [...] but I don’t really get in which form the dataset needs to be, so that it’s fine for the pretrained model. Especially I don’t get how to give the labels correctly for training."""
,,Loading/Saving Datasets,"Issues/Questions about reading or writing datasets from/to remore or local locations, dataloaders, loading large datasets, etc.","T27423: ""I save a dataset to disk. Later, I load it from disk in a different script. I add some items. I try to save to disk again. I get the error “PermissionError: Tried to overwrite [path]/dataset.arrow but a dataset can’t overwrite itself.”. How do I solve this? What is the correct way to add new rows the dataset on disk?"""
,,Asking for a Special Dataset for a Certain Task,"Users asking for a special dataset, a dataset with a special feature or for suggestions for datasets for a special task/mode.","T22364: ""I would like to fine tune an English language ASR model using Spanish-accented English dataset, but the most common datasets doesn’t offer what I need, for example, Common Voice offers several accents but none of them from spanish speaking countries and LibriSpeech features doesn’t include any reference to accents or speaker’s origin that could be used to discriminate the data. Could you suggets another source I could resort to?"""
,,External Datasets,"Questions raised when working with datasets from other platforms, e.g. Kaggle.","T22280: ""I am working on a Named Entity Recognition project. This is the data that I am working with is Named Entity Recognition (NER) Corpus | Kaggle. When I try to map the tokenize_and_align_labels function, i get the following error[...] How do I convert just those two columns to lists (or sequences) of strings?"""
,,Other Dataset Issues,All the other issues regardinh datasets that do not fit in any of the categories above. All issues regarding HF datasets library.,"T25554: ""In the ._info() method, for the dataset generator class, I noticed there isn’t a task template for multi-label problems [...] What is the purpose of the task_templates attributes? What are the advantages to have one task templates for a multi-label image problem?"
7,Specific Solution Need,,"When user asks for suggestion, solution, or code for a special scenario or a specific task.","T11271: ""How can I perform a Question-Answering system that returns Yes or No to my questions?"""
8,Incomprehensible output,,When the users cannot justify or comprehend the output produced by the model.,"T12350: ""I’m getting these random output errors maybe 1/50 times I process a sentence. [...] This is the number for some random pizza place. Why does it keep appearing in my output."""
9,HF Libraries' Features,Implementation of HF Source code/Existing Feature,"Questions about the availability of features in HF, and the implementation of HF libraries source code.","T18981: ""I’ve trained Roberta for a token classification task, and unfortunately some of my input text are just over 512 tokens long. [...]I read somewhere that there’s a chunk pipeline in huggingface that analyzes over-lapping chunks and then averages out the predictions on the overlapping segments. Is there a way for me to access the components of this chunking pipeline outside of actually using the full pipeline for inference?"""
,,Request Feature Model,Asking for a specific feature/model to be uploaded or implemented.,"T16319: ""Can some one please upload Wav2Vec2-XLS-R(0.3 B) with Language Identifcation downstream task ? can’t seem to find those on model hub and source repo."""
10,API Usage,API usage,"Asking for the right API for doing a specific action, asking about the usage of APIs, issues encountered when calling APIs. ","T23843: ""I could pass past_key_values as an argument in model.generate() so that it wouldn’t repeatedly compute the key, values of the shared prefix. However, how do I get this past_key_values? The generate() function returns a GreedySearchDecoderOnlyOutput object (I set beam size = 1, no sampling), which does not contain past_key_values. It’s only in the return of model.forward()?"""
,,REST API,Errors and issues regarding the HF Rest API.,"T28987: ""I was experimenting with the REST API with a private repo. Despite providing the user access token in the request header, I receive an error[...] The load_dataset() works in private mode when I set the use_auth_token argument. Any clue what I missing here?"""
11,Website & Pricing,Website,"Issues with the design of the HF website, the timeouts for downloading, the dfferent webserver errors.","T26595: ""I am stuck at 3:35 as when I input what (i think) is my username and the token, it says i have not accepted terms and conditions. I believe this is in relation to the website part which is here:[...] But I dont know how I am supposed to accept terms and conditions when they are not there?"""
,,File not found,"Issues regarding the ""file not found"" error or missing model, dataset, etc. files on the server.","T10245: ""i get this error while trying to load /tuner007/pegasus_paraphrase/ model [...] 404 Client Error: Not Found for url: https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/tf_model.h5"""
,,Pricing,"Issues with the paid services of HF, their pricing, and their support.","T13252: ""I deleted the project (because I didn’t see any other option) and created a new one. My second project is now informing me i’ll need to pay. I’m aware you kindly offer one free project, but since my initial project failed it seems reasonable to roll it over to the next project."""
12,Lack of Support,,"Questions without answer, or beginners collaboration to try to solve issue","T31043: ""I am facing the issue of not being able to fine-tune mt5-small with fp16. There are a few discussions regarding the issue but there is no concrete fixed or those fixed are not merged into the main branch yet.[...] Any recommendation or solution?Thanks the community"
13,Spaces,,"Issues that are relatdd to creating, modifying, or using HF spaces.","T19747: ""I’m trying to upload my app on Spaces. This app built with gradio works on my computer but I have a build error without any explanation (no log).[...]anyone knows something about this issue"""
14,Inference & Deployment,Inference Endpoints,Questions/Issues about using the HF Inference Endpoints,"T42099: ""I want to specify a hypothesis template when using the inference endpoint for zero shot text classification with the facebook/bart-large-mnli 1 model but I can not find any indication in the documentation as to how to do this. Any help would be greatly appreciated."""
,,Inference Pipeline,Issues in usig/making inference pipelines.,"T35497: ""I can initialize it it with AutoModelForCausalLM.from_pretrained it downloads and loads the model. However when I try to create a pipeline it fails."""
,,Deployment & Production,Issues/questions regarding app deployment and production,"T2854: ""Hi everyone! : [...] I’ve an issue with a Streamlit app leveraging Pytorch with the distilbart-mnli-12-3 HuggingFace model. I can’t seem to deploy it correctly on Heroku. I’ve tried various configs but once deployed the app crashes all time. [...]"""
15,Privacy & Security,,"Questions regarding security, private model, private dataset, ...","T17227: ""Is there a risk of my data getting leaked via nefarious code being added to a model repo, or by being sent to Hugging face when using the transformers library?"""
16,Onboarding,,"The user is novice in HF/ML and usually asking question about installation, making their first repo, initialising their first environment, or ask where to start.","T16994: ""Hi, Most of the tutorials I have seen focus on loading existing large models. I have a custom model + saved weights. How can I upload this to hugging face hub?[...]"""
17,Other Issues,,Anything not included in one of the categories above,"T31048: ""Is it pronounced “G radio” or “gradio”?"""